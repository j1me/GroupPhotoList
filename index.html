<!DOCTYPE html>
<html>
<head>
    <title>FaceFrame - Privacy-First Face Detection</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.12/dist/face-api.js"></script>
    <style>
        .gradient-bg { background: linear-gradient(180deg, #EBF4FF 0%, #F3E8FF 100%); }
        .drag-area { transition: all 0.3s ease; }
        .drag-area.active { background-color: rgba(59, 130, 246, 0.1); }
        #temp-canvas { display: none; }
        .notification {
            position: fixed;
            bottom: 1rem;
            right: 1rem;
            padding: 1rem;
            border-radius: 0.5rem;
            animation: slideIn 0.3s ease-out;
        }
        @keyframes slideIn {
            from { transform: translateX(100%); }
            to { transform: translateX(0); }
        }
    </style>
</head>
<body class="gradient-bg min-h-screen">
    <div class="p-4 sm:p-6 lg:p-8 flex flex-col min-h-screen">
        <!-- Header -->
        <header class="text-center mb-8">
            <div class="inline-flex items-center justify-center flex-col">
                <h1 class="text-4xl font-bold text-blue-800">FaceFrame</h1>
                <p class="mt-2 text-gray-600">Privacy-first face detection - your photos never leave your browser</p>
            </div>
        </header>

        <!-- Main Content -->
        <main class="flex-grow">
            <div class="bg-white rounded-lg shadow-lg max-w-4xl mx-auto p-6">
                <h2 class="text-2xl font-semibold text-gray-800 mb-6">How it works</h2>
                
                <!-- Process Steps -->
                <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-8">
                    <div class="text-center">
                        <img src="assets/upload.svg" alt="Upload" class="w-24 h-24 mx-auto mb-2">
                        <p class="text-sm text-gray-600">1. Upload a group photo</p>
                    </div>
                    <div class="text-center">
                        <img src="assets/process.svg" alt="Process" class="w-24 h-24 mx-auto mb-2">
                        <p class="text-sm text-gray-600">2. AI detects faces</p>
                    </div>
                    <div class="text-center">
                        <img src="assets/result.svg" alt="Result" class="w-24 h-24 mx-auto mb-2">
                        <p class="text-sm text-gray-600">3. View individual faces</p>
                    </div>
                </div>

                <!-- Upload Area -->
                <div id="loading" class="hidden text-center p-8">
                    <div class="animate-spin rounded-full h-12 w-12 border-b-2 border-blue-500 mx-auto"></div>
                    <p class="mt-4 text-gray-600" id="loading-text">Loading model...</p>
                </div>

                <div id="upload-area" class="drag-area border-2 border-dashed border-blue-300 rounded-lg p-8 text-center bg-blue-50 transition-all hover:bg-blue-100">
                    <svg class="mx-auto h-12 w-12 text-blue-500" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12"/>
                    </svg>
                    <p class="mt-4 text-sm font-medium text-gray-600">
                        Drag and drop your image here, or
                    </p>
                    <button onclick="document.getElementById('file-input').click()" 
                            class="mt-2 bg-blue-500 hover:bg-blue-600 text-white font-semibold py-2 px-4 rounded inline-flex items-center transition duration-300">
                        <svg class="w-4 h-4 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16l4.586-4.586a2 2 0 012.828 0L16 16m-2-2l1.586-1.586a2 2 0 012.828 0L20 14m-6-6h.01M6 20h12a2 2 0 002-2V6a2 2 0 00-2-2H6a2 2 0 00-2 2v12a2 2 0 002 2z"/>
                        </svg>
                        Choose file
                    </button>
                    <input type="file" id="file-input" class="hidden" accept="image/*">
                    <p class="mt-1 text-xs text-gray-500">
                        Supports: JPG, PNG, GIF. Processing is done locally in your browser.
                    </p>
                </div>

                <!-- Results Area -->
                <div id="results" class="hidden mt-8">
                    <h2 class="text-2xl font-semibold text-gray-800 mb-4">Original Photo</h2>
                    <img id="original-image" class="w-full rounded-lg shadow-md mb-8" src="" alt="Original photo">
                    <h2 class="text-2xl font-semibold text-gray-800 mb-4">Detected Faces</h2>
                    <div id="faces-grid" class="grid grid-cols-2 md:grid-cols-3 gap-4"></div>
                </div>
            </div>
        </main>

        <!-- Footer -->
        <footer class="mt-8 text-center">
            <a href="about.html" class="text-blue-600 hover:text-blue-800 font-medium">About FaceFrame</a>
        </footer>

        <!-- Notification -->
        <div id="notification" class="notification hidden"></div>
    </div>

    <canvas id="temp-canvas"></canvas>
    <script>
        let isModelLoaded = false;
        let currentImage = null;

        // Initialize face detection
        async function loadModel() {
            try {
                console.log('Loading face detection model...');
                
                // Initialize TensorFlow.js
                await tf.ready();
                await tf.setBackend('webgl');

                // Load face-api.js models
                const faceDetectionNet = faceapi.nets.ssdMobilenetv1;
                await faceDetectionNet.load('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
                
                // Configure face detection parameters
                const minConfidence = 0.5;
                const options = new faceapi.SsdMobilenetv1Options({ minConfidence });
                faceapi.detectAllFaces = (input) => faceDetectionNet.detectFaces(input, options);

                isModelLoaded = true;
                console.log('Face detection model loaded successfully');
            } catch (error) {
                console.error('Error loading model:', error);
                throw error;
            }
        }

        // Process image
        async function processImage(img) {
            try {
                const faceDetections = await faceapi.detectAllFaces(img);
                const detections = faceDetections.map(det => ({
                    detection: {
                        box: {
                            x: det._box._x,
                            y: det._box._y,
                            width: det._box._width,
                            height: det._box._height
                        }
                    }
                }));

                if (!detections || detections.length === 0) {
                    throw new Error('No faces detected in the image');
                }

                processDetections(detections, img);
            } catch (error) {
                console.error('Error in face detection:', error);
                throw new Error(`Face detection failed: ${error.message}`);
            }
        }

        // Process detections and create face crops
        function processDetections(detections, image) {
            const faces = [];
            
            detections.forEach((detection, index) => {
                const box = detection.detection.box;
                
                // Add padding around face
                const padding = Math.min(box.width, box.height) * 0.2;
                const paddedX = Math.max(0, box.x - padding);
                const paddedY = Math.max(0, box.y - padding);
                const paddedWidth = Math.min(box.width + 2 * padding, image.width - paddedX);
                const paddedHeight = Math.min(box.height + 2 * padding, image.height - paddedY);

                // Create face canvas
                const faceCanvas = document.createElement('canvas');
                faceCanvas.width = paddedWidth;
                faceCanvas.height = paddedHeight;
                const faceCtx = faceCanvas.getContext('2d');
                faceCtx.drawImage(image, paddedX, paddedY, paddedWidth, paddedHeight, 0, 0, paddedWidth, paddedHeight);
                
                // Store face data
                faces.push(faceCanvas.toDataURL());
            });

            // Store results in localStorage
            localStorage.setItem('originalImage', image.src);
            localStorage.setItem('faces', JSON.stringify(faces));

            // Redirect to results page
            window.location.href = 'results.html';
        }

        async function handleFiles(files) {
            if (!isModelLoaded) {
                alert('Please wait for the face detection model to load');
                return;
            }

            if (files.length === 0) return;
            
            const file = files[0];
            if (!file.type.startsWith('image/')) {
                alert('Please upload an image file');
                return;
            }

            loading.classList.remove('hidden');
            results.classList.add('hidden');

            try {
                currentImage = await loadImage(file);
                originalImage.src = currentImage.src;
                await processImage(currentImage);
            } catch (error) {
                console.error('Error processing image:', error);
                loading.classList.add('hidden');
                alert('An error occurred while processing the image: ' + error.message);
            }
        }

        async function loadImage(file) {
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.onload = () => resolve(img);
                img.onerror = reject;
                img.src = URL.createObjectURL(file);
            });
        }

        // DOM elements
        const dragArea = document.querySelector('.drag-area');
        const fileInput = document.getElementById('file-input');
        const loading = document.getElementById('loading');
        const results = document.getElementById('results');
        const originalImage = document.getElementById('original-image');
        const facesGrid = document.getElementById('faces-grid');
        const tempCanvas = document.getElementById('temp-canvas');
        const tempCtx = tempCanvas.getContext('2d');

        // Handle drag and drop
        ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
            dragArea.addEventListener(eventName, preventDefaults, false);
        });

        function preventDefaults(e) {
            e.preventDefault();
            e.stopPropagation();
        }

        ['dragenter', 'dragover'].forEach(eventName => {
            dragArea.addEventListener(eventName, () => dragArea.classList.add('active'));
        });

        ['dragleave', 'drop'].forEach(eventName => {
            dragArea.addEventListener(eventName, () => dragArea.classList.remove('active'));
        });

        dragArea.addEventListener('drop', handleDrop, false);
        fileInput.addEventListener('change', handleFileSelect, false);

        function handleDrop(e) {
            handleFiles(e.dataTransfer.files);
        }

        function handleFileSelect(e) {
            handleFiles(e.target.files);
        }

        // Initialize on page load
        window.addEventListener('load', async () => {
            try {
                await loadModel();
            } catch (error) {
                console.error('Failed to initialize model:', error);
                alert('Failed to load face detection model. Please try refreshing the page.');
            }
        });

        function showNotification(type, message) {
            const notification = document.getElementById('notification');
            notification.className = `notification ${type === 'success' ? 'bg-green-500' : 'bg-red-500'} text-white`;
            notification.textContent = message;
            notification.classList.remove('hidden');
            setTimeout(() => {
                notification.classList.add('hidden');
            }, 3000);
        }

        // Update loading states
        function updateLoadingState(stage) {
            const loadingText = document.getElementById('loading-text');
            loadingText.textContent = stage === 'initializing' 
                ? 'Loading face detection model...' 
                : 'Processing image...';
        }
    </script>
</body>
</html>
