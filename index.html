<!DOCTYPE html>
<html>
<head>
    <title>Group Photo Face Detection</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <!-- Load MediaPipe Face Detection -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/vision_bundle.js" crossorigin="anonymous"></script>
    <style>
        .drag-area { border: 2px dashed #4CAF50; transition: all 0.3s ease; }
        .drag-area.active { border-color: #2196F3; background-color: rgba(33, 150, 243, 0.1); }
        #temp-canvas { display: none; }
    </style>
</head>
<body class="bg-gray-100 min-h-screen">
    <div class="container mx-auto px-4 py-8">
        <h1 class="text-3xl font-bold text-center mb-8">Group Photo Face Detection</h1>
        <div class="max-w-2xl mx-auto">
            <div class="drag-area bg-white p-8 rounded-lg shadow-md text-center mb-8">
                <div class="mb-4">
                    <svg class="mx-auto h-12 w-12 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
                              d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12"/>
                    </svg>
                </div>
                <p class="text-gray-600 mb-4">Drag & Drop your group photo here or</p>
                <input type="file" id="file-input" class="hidden" accept="image/*">
                <button onclick="document.getElementById('file-input').click()" 
                        class="bg-blue-500 hover:bg-blue-600 text-white font-semibold py-2 px-4 rounded transition duration-300">
                    Choose File
                </button>
            </div>
            <div id="loading" class="hidden text-center mb-8">
                <div class="animate-spin rounded-full h-12 w-12 border-b-2 border-blue-500 mx-auto"></div>
                <p class="mt-4 text-gray-600">Processing image...</p>
            </div>
            <div id="results" class="hidden">
                <h2 class="text-2xl font-semibold mb-4">Original Photo</h2>
                <img id="original-image" class="w-full rounded-lg shadow-md mb-8" src="" alt="Original photo">
                <h2 class="text-2xl font-semibold mb-4">Detected Faces</h2>
                <div id="faces-grid" class="grid grid-cols-2 md:grid-cols-3 gap-4"></div>
            </div>
        </div>
    </div>
    <canvas id="temp-canvas"></canvas>
    <script>
        let faceDetector = null;
        let isModelLoaded = false;

        // Initialize MediaPipe Face Detection
        async function loadModel() {
            try {
                console.log('Loading MediaPipe Face Detection...');
                
                const vision = await FilesetResolver.forVisionTasks(
                    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
                );
                
                faceDetector = await FaceDetector.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short/float16/1/blaze_face_short.tflite",
                        delegate: "GPU"
                    },
                    runningMode: "IMAGE",
                    minDetectionConfidence: 0.5
                });

                isModelLoaded = true;
                console.log('MediaPipe Face Detection loaded successfully');
            } catch (error) {
                console.error('Error loading model:', error);
                throw error;
            }
        }

        // Wait for page to load before initializing
        window.addEventListener('load', () => {
            console.log('Page loaded, starting model initialization...');
            loadModel().catch(error => {
                console.error('Failed to initialize model:', error);
                alert('Failed to load face detection model. Please try refreshing the page.');
            });
        });

        const dragArea = document.querySelector('.drag-area');
        const fileInput = document.getElementById('file-input');
        const loading = document.getElementById('loading');
        const results = document.getElementById('results');
        const originalImage = document.getElementById('original-image');
        const facesGrid = document.getElementById('faces-grid');
        const tempCanvas = document.getElementById('temp-canvas');
        const tempCtx = tempCanvas.getContext('2d');

        ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
            dragArea.addEventListener(eventName, preventDefaults, false);
        });

        function preventDefaults(e) {
            e.preventDefault();
            e.stopPropagation();
        }

        ['dragenter', 'dragover'].forEach(eventName => {
            dragArea.addEventListener(eventName, () => dragArea.classList.add('active'));
        });

        ['dragleave', 'drop'].forEach(eventName => {
            dragArea.addEventListener(eventName, () => dragArea.classList.remove('active'));
        });

        dragArea.addEventListener('drop', handleDrop, false);
        fileInput.addEventListener('change', handleFileSelect, false);

        function handleDrop(e) {
            handleFiles(e.dataTransfer.files);
        }

        function handleFileSelect(e) {
            handleFiles(e.target.files);
        }

        async function loadImage(file) {
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.onload = () => resolve(img);
                img.onerror = reject;
                img.src = URL.createObjectURL(file);
            });
        }

        // Process detections and create face crops
        function processDetections(detections) {
            facesGrid.innerHTML = '';
            console.log('Processing detections:', detections);
            
            detections.forEach((detection, index) => {
                const bbox = detection.boundingBox;
                const width = bbox.width;
                const height = bbox.height;
                const x = bbox.originX;
                const y = bbox.originY;
                
                // Add padding around face
                const padding = Math.min(width, height) * 0.2;
                const paddedX = Math.max(0, x - padding);
                const paddedY = Math.max(0, y - padding);
                const paddedWidth = Math.min(width + 2 * padding, tempCanvas.width - paddedX);
                const paddedHeight = Math.min(height + 2 * padding, tempCanvas.height - paddedY);

                // Create face canvas
                const faceCanvas = document.createElement('canvas');
                faceCanvas.width = paddedWidth;
                faceCanvas.height = paddedHeight;
                const faceCtx = faceCanvas.getContext('2d');
                faceCtx.drawImage(tempCanvas, paddedX, paddedY, paddedWidth, paddedHeight, 0, 0, paddedWidth, paddedHeight);

                // Create face element
                const faceElement = document.createElement('div');
                faceElement.className = 'bg-white p-4 rounded-lg shadow-md';
                
                // Create face image with Google Lens search link
                const faceLink = document.createElement('a');
                faceLink.href = `https://lens.google.com/uploadbyurl?url=${encodeURIComponent(faceCanvas.toDataURL())}`;
                faceLink.target = '_blank';
                faceLink.innerHTML = `
                    <img src="${faceCanvas.toDataURL()}" class="w-full h-48 object-cover rounded" alt="Face ${index + 1}">
                    <p class="mt-2 text-center text-gray-600">Person ${index + 1}</p>
                `;
                
                faceElement.appendChild(faceLink);
                facesGrid.appendChild(faceElement);
            });

            loading.classList.add('hidden');
            results.classList.remove('hidden');
        }

        async function handleFiles(files) {
            if (!isModelLoaded) {
                alert('Please wait for the face detection model to load');
                return;
            }

            if (files.length === 0) return;
            
            const file = files[0];
            if (!file.type.startsWith('image/')) {
                alert('Please upload an image file');
                return;
            }

            loading.classList.remove('hidden');
            results.classList.add('hidden');

            try {
                console.log('Loading image...');
                const img = await loadImage(file);
                console.log('Image loaded, dimensions:', img.width, 'x', img.height);

                // Display original image
                originalImage.src = img.src;

                // Set canvas dimensions
                tempCanvas.width = img.width;
                tempCanvas.height = img.height;
                tempCtx.drawImage(img, 0, 0);

                console.log('Running face detection...');
                try {
                    const detections = await faceDetector.detect(img);
                    console.log('Face detection completed successfully:', detections);
                    if (detections.detections) {
                        processDetections(detections.detections);
                    }
                } catch (detectionError) {
                    console.error('Face detection error:', detectionError);
                    console.log('Face detector state:', faceDetector);
                    throw new Error(`Face detection failed: ${detectionError.message}`);
                }
            } catch (error) {
                console.error('Error processing image:', error);
                loading.classList.add('hidden');
                alert('An error occurred while processing the image: ' + error.message);
            }
        }
    </script>
</body>
</html>
